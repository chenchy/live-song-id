{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Known-Artist Live Song ID: A Hashprint Approach\n",
    "\n",
    "This notebook is a python implementation of the [original matlab version] (http://pages.hmc.edu/ttsai/assets/livesongid.tar.gz). The pipeline consists of the following modules:\n",
    "\n",
    "1. Preprocessing with Constant-Q Transform (CQT)\n",
    "2. Learning PCA filters\n",
    "3. Obtaining hashprint representation by applying PCA filters to preprocessed CQT matrix\n",
    "4. Generating database with the hashprint of pitch-shifted CQT matrix of reference tracks\n",
    "5. Matching query against database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T07:38:23.172248Z",
     "start_time": "2018-02-07T07:38:23.163668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhwang/workspace/live-song-id\n"
     ]
    }
   ],
   "source": [
    "GIT_DIR = '/home/zhwang/workspace/live-song-id/'\n",
    "%cd $GIT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "For a given artist, we first preprocess the list of reference tracks by taking CQT transform for each audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T07:38:25.494997Z",
     "start_time": "2018-02-07T07:38:24.803612Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "import os\n",
    "from utils import pitch_shift_CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T07:38:26.314360Z",
     "start_time": "2018-02-07T07:38:26.304880Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# audio_path - where audio files are stored\n",
    "# list_dir - where list of softlinks are stored\n",
    "# cqt_dir - where results will be stored\n",
    "audio_path = '/home/nbanerjee/SoftLinks/'\n",
    "list_dir = audio_path + '/Lists/'\n",
    "cqt_dir = '/home/zhwang/ttemp/livesong_results/' # change this\n",
    "artist = 'taylorswift'\n",
    "out_dir = os.path.join(cqt_dir, artist+'_out')\n",
    "file_paths = get_allpaths(artist, list_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T07:57:29.917108Z",
     "start_time": "2018-02-07T07:41:31.282369Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%cd $cqt_dir\n",
    "%mkdir $out_dir\n",
    "%cd $out_dir\n",
    "\n",
    "f = open(os.path.join(out_dir, artist + '_cqtList.txt'), 'w')\n",
    "for cur_file in file_paths:\n",
    "    print('==> Computing CQT of %s'%cur_file)\n",
    "    y, sr = librosa.load(audio_path + cur_file + '.wav')\n",
    "    Q = librosa.cqt(y, sr=sr, fmin=130.81, n_bins=121, bins_per_octave=24)\n",
    "    logQ = preprocess(Q, 3)\n",
    "    cur_file_path = os.path.join(os.getcwd(), cur_file + '.dat')\n",
    "    np.savetxt(cur_file_path, logQ)\n",
    "    f.write(cur_file_path + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning PCA Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T08:09:42.272674Z",
     "start_time": "2018-02-07T08:09:42.266333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhwang/workspace/live-song-id\n"
     ]
    }
   ],
   "source": [
    "%cd $GIT_DIR\n",
    "from PCA import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate the filters for the hashprint representation by taking PCA on the covariance matrix for all reference songs for this artist. First, we compute the covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T08:09:43.341342Z",
     "start_time": "2018-02-07T08:09:43.334853Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "nbins = 121\n",
    "m = 20 # number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T08:11:10.811072Z",
     "start_time": "2018-02-07T08:09:44.286845Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing covariance matrix for taylorswift_ref1.dat\n",
      "==> Computing covariance matrix for taylorswift_ref2.dat\n",
      "==> Computing covariance matrix for taylorswift_ref3.dat\n",
      "==> Computing covariance matrix for taylorswift_ref4.dat\n",
      "==> Computing covariance matrix for taylorswift_ref5.dat\n",
      "==> Computing covariance matrix for taylorswift_ref6.dat\n",
      "==> Computing covariance matrix for taylorswift_ref7.dat\n",
      "==> Computing covariance matrix for taylorswift_ref8.dat\n",
      "==> Computing covariance matrix for taylorswift_ref9.dat\n",
      "==> Computing covariance matrix for taylorswift_ref10.dat\n",
      "==> Computing covariance matrix for taylorswift_ref11.dat\n",
      "==> Computing covariance matrix for taylorswift_ref12.dat\n",
      "==> Computing covariance matrix for taylorswift_ref13.dat\n",
      "==> Computing covariance matrix for taylorswift_ref14.dat\n",
      "==> Computing covariance matrix for taylorswift_ref15.dat\n",
      "==> Computing covariance matrix for taylorswift_ref16.dat\n",
      "==> Computing covariance matrix for taylorswift_ref17.dat\n",
      "==> Computing covariance matrix for taylorswift_ref18.dat\n",
      "==> Computing covariance matrix for taylorswift_ref19.dat\n",
      "==> Computing covariance matrix for taylorswift_ref20.dat\n",
      "==> Computing covariance matrix for taylorswift_ref21.dat\n",
      "==> Computing covariance matrix for taylorswift_ref22.dat\n",
      "==> Computing covariance matrix for taylorswift_ref23.dat\n",
      "==> Computing covariance matrix for taylorswift_ref24.dat\n",
      "==> Computing covariance matrix for taylorswift_ref25.dat\n",
      "==> Computing covariance matrix for taylorswift_ref26.dat\n",
      "==> Computing covariance matrix for taylorswift_ref27.dat\n",
      "==> Computing covariance matrix for taylorswift_ref28.dat\n",
      "==> Computing covariance matrix for taylorswift_ref29.dat\n",
      "==> Computing covariance matrix for taylorswift_ref30.dat\n",
      "==> Computing covariance matrix for taylorswift_ref31.dat\n",
      "==> Computing covariance matrix for taylorswift_ref32.dat\n",
      "==> Computing covariance matrix for taylorswift_ref33.dat\n",
      "==> Computing covariance matrix for taylorswift_ref34.dat\n",
      "==> Computing covariance matrix for taylorswift_ref35.dat\n",
      "==> Computing covariance matrix for taylorswift_ref36.dat\n",
      "==> Computing covariance matrix for taylorswift_ref37.dat\n",
      "==> Computing covariance matrix for taylorswift_ref38.dat\n",
      "==> Computing covariance matrix for taylorswift_ref39.dat\n",
      "==> Computing covariance matrix for taylorswift_ref40.dat\n",
      "==> Computing covariance matrix for taylorswift_ref41.dat\n",
      "==> Computing covariance matrix for taylorswift_ref42.dat\n",
      "==> Computing covariance matrix for taylorswift_ref43.dat\n",
      "==> Computing covariance matrix for taylorswift_ref44.dat\n",
      "==> Computing covariance matrix for taylorswift_ref45.dat\n",
      "==> Computing covariance matrix for taylorswift_ref46.dat\n",
      "==> Computing covariance matrix for taylorswift_ref47.dat\n",
      "==> Computing covariance matrix for taylorswift_ref48.dat\n",
      "==> Computing covariance matrix for taylorswift_ref49.dat\n",
      "==> Computing covariance matrix for taylorswift_ref50.dat\n",
      "==> Computing covariance matrix for taylorswift_ref51.dat\n",
      "==> Computing covariance matrix for taylorswift_ref52.dat\n",
      "==> Computing covariance matrix for taylorswift_ref53.dat\n",
      "==> Computing covariance matrix for taylorswift_ref54.dat\n",
      "==> Computing covariance matrix for taylorswift_ref55.dat\n",
      "==> Computing covariance matrix for taylorswift_ref56.dat\n",
      "==> Computing covariance matrix for taylorswift_ref57.dat\n",
      "==> Computing covariance matrix for taylorswift_ref58.dat\n",
      "==> Computing covariance matrix for taylorswift_ref59.dat\n",
      "==> Computing covariance matrix for taylorswift_ref60.dat\n",
      "==> Computing covariance matrix for taylorswift_ref61.dat\n",
      "==> Computing covariance matrix for taylorswift_ref62.dat\n",
      "==> Computing covariance matrix for taylorswift_ref63.dat\n",
      "==> Computing covariance matrix for taylorswift_ref64.dat\n",
      "==> Computing covariance matrix for taylorswift_ref65.dat\n",
      "==> Computing covariance matrix for taylorswift_ref66.dat\n",
      "==> Computing covariance matrix for taylorswift_ref67.dat\n",
      "==> Computing covariance matrix for taylorswift_ref68.dat\n",
      "==> Computing covariance matrix for taylorswift_ref69.dat\n",
      "==> Computing covariance matrix for taylorswift_ref70.dat\n",
      "==> Computing covariance matrix for taylorswift_ref71.dat\n"
     ]
    }
   ],
   "source": [
    "f = open(os.path.join(out_dir, artist + '_cqtList.txt'), 'r')\n",
    "accum_cov = np.zeros((nbins * m, nbins * m))\n",
    "count = 0\n",
    "\n",
    "for line in f:\n",
    "    print('==> Computing covariance matrix for %s'%os.path.basename(line)[:-1])\n",
    "    Q = np.loadtxt(line[:-1])\n",
    "    A = getTDE(Q)\n",
    "    if A.shape[1] > 1:\n",
    "        accum_cov += np.cov(A.T)\n",
    "    count += 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute PCA from these covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T08:15:04.142290Z",
     "start_time": "2018-02-07T08:14:59.051592Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "evals, evecs = LA.eig(accum_cov / count)\n",
    "ind = np.argsort(-evals)\n",
    "evecs = (evecs[:, ind])[:, :num_features] # this turns out to be complex\n",
    "evecs = np.absolute(evecs)\n",
    "np.savetxt(os.path.join(out_dir, artist + '_model.dat'), evecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Filters to CQT Matrix to generate the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:09:17.985882Z",
     "start_time": "2018-02-07T09:09:17.697286Z"
    }
   },
   "outputs": [],
   "source": [
    "evecs = np.loadtxt(os.path.join(out_dir, artist + '_model.dat')).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to stay consistency with the keras model, we transpose the filters and the CQT images to have shape ```(width, height)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:09:19.635621Z",
     "start_time": "2018-02-07T09:09:19.628249Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_matrix = np.array([vec.reshape((m, -1)) for vec in evecs])\n",
    "delta = 16\n",
    "max_pitch_shift = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each reference track, we pitch shift the CQT matrix by four pitches, both up and down. For each pitch-shifted version, we compute the hashprint by first passing it through the convolutional network, and then taking the delta feature and thresholding by zero.\n",
    "\n",
    "The database contains filenames as keys and the pitch-shifted delta features as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:10:01.359591Z",
     "start_time": "2018-02-07T09:09:21.358407Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generating database for taylorswift_ref1.dat\n",
      "==> Generating database for taylorswift_ref2.dat\n",
      "==> Generating database for taylorswift_ref3.dat\n",
      "==> Generating database for taylorswift_ref4.dat\n",
      "==> Generating database for taylorswift_ref5.dat\n",
      "==> Generating database for taylorswift_ref6.dat\n",
      "==> Generating database for taylorswift_ref7.dat\n",
      "==> Generating database for taylorswift_ref8.dat\n",
      "==> Generating database for taylorswift_ref9.dat\n",
      "==> Generating database for taylorswift_ref10.dat\n",
      "==> Generating database for taylorswift_ref11.dat\n",
      "==> Generating database for taylorswift_ref12.dat\n",
      "==> Generating database for taylorswift_ref13.dat\n",
      "==> Generating database for taylorswift_ref14.dat\n",
      "==> Generating database for taylorswift_ref15.dat\n",
      "==> Generating database for taylorswift_ref16.dat\n",
      "==> Generating database for taylorswift_ref17.dat\n",
      "==> Generating database for taylorswift_ref18.dat\n",
      "==> Generating database for taylorswift_ref19.dat\n",
      "==> Generating database for taylorswift_ref20.dat\n",
      "==> Generating database for taylorswift_ref21.dat\n",
      "==> Generating database for taylorswift_ref22.dat\n",
      "==> Generating database for taylorswift_ref23.dat\n",
      "==> Generating database for taylorswift_ref24.dat\n",
      "==> Generating database for taylorswift_ref25.dat\n",
      "==> Generating database for taylorswift_ref26.dat\n",
      "==> Generating database for taylorswift_ref27.dat\n",
      "==> Generating database for taylorswift_ref28.dat\n",
      "==> Generating database for taylorswift_ref29.dat\n",
      "==> Generating database for taylorswift_ref30.dat\n",
      "==> Generating database for taylorswift_ref31.dat\n",
      "==> Generating database for taylorswift_ref32.dat\n",
      "==> Generating database for taylorswift_ref33.dat\n",
      "==> Generating database for taylorswift_ref34.dat\n",
      "==> Generating database for taylorswift_ref35.dat\n",
      "==> Generating database for taylorswift_ref36.dat\n",
      "==> Generating database for taylorswift_ref37.dat\n",
      "==> Generating database for taylorswift_ref38.dat\n",
      "==> Generating database for taylorswift_ref39.dat\n",
      "==> Generating database for taylorswift_ref40.dat\n",
      "==> Generating database for taylorswift_ref41.dat\n",
      "==> Generating database for taylorswift_ref42.dat\n",
      "==> Generating database for taylorswift_ref43.dat\n",
      "==> Generating database for taylorswift_ref44.dat\n",
      "==> Generating database for taylorswift_ref45.dat\n",
      "==> Generating database for taylorswift_ref46.dat\n",
      "==> Generating database for taylorswift_ref47.dat\n",
      "==> Generating database for taylorswift_ref48.dat\n",
      "==> Generating database for taylorswift_ref49.dat\n",
      "==> Generating database for taylorswift_ref50.dat\n",
      "==> Generating database for taylorswift_ref51.dat\n",
      "==> Generating database for taylorswift_ref52.dat\n",
      "==> Generating database for taylorswift_ref53.dat\n",
      "==> Generating database for taylorswift_ref54.dat\n",
      "==> Generating database for taylorswift_ref55.dat\n",
      "==> Generating database for taylorswift_ref56.dat\n",
      "==> Generating database for taylorswift_ref57.dat\n",
      "==> Generating database for taylorswift_ref58.dat\n",
      "==> Generating database for taylorswift_ref59.dat\n",
      "==> Generating database for taylorswift_ref60.dat\n",
      "==> Generating database for taylorswift_ref61.dat\n",
      "==> Generating database for taylorswift_ref62.dat\n",
      "==> Generating database for taylorswift_ref63.dat\n",
      "==> Generating database for taylorswift_ref64.dat\n",
      "==> Generating database for taylorswift_ref65.dat\n",
      "==> Generating database for taylorswift_ref66.dat\n",
      "==> Generating database for taylorswift_ref67.dat\n",
      "==> Generating database for taylorswift_ref68.dat\n",
      "==> Generating database for taylorswift_ref69.dat\n",
      "==> Generating database for taylorswift_ref70.dat\n",
      "==> Generating database for taylorswift_ref71.dat\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "\n",
    "f = open(os.path.join(out_dir, artist + '_cqtList.txt'), 'r')\n",
    "db = {}\n",
    "\n",
    "for line in f:\n",
    "    print('==> Generating database for %s'%os.path.basename(line)[:-1])\n",
    "    Q = np.loadtxt(line[:-1]).T\n",
    "    pitch_shift_Qs = np.empty((2 * max_pitch_shift + 1, ) + Q.shape)\n",
    "    pitch_shift_Qs[0, :, :] = Q\n",
    "    for i in range(1, max_pitch_shift + 1):\n",
    "        pitch_shift_Qs[i, :, :] = pitch_shift_CQT(Q.T, i).T\n",
    "    for i in range(1, max_pitch_shift + 1):\n",
    "        pitch_shift_Qs[i + max_pitch_shift, :, :] = pitch_shift_CQT(Q.T, -i).T\n",
    "    \n",
    "    conv_1d_net = build_model(pca_matrix, Q.shape, delta=delta)\n",
    "    \n",
    "    fpseqs = run_model(conv_1d_net, pitch_shift_Qs)\n",
    "    delta_fp = fpseqs[:, :, :fpseqs.shape[2] - delta] - fpseqs[:, :, delta:]\n",
    "    \n",
    "    db[os.path.basename(line)[:-1]] = np.where(delta_fp > 0, 1, 0)\n",
    "f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the database, we serialize it and save it to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:13:29.939852Z",
     "start_time": "2018-02-07T09:13:29.935371Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "db_path = os.path.join(out_dir, artist + '_db.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:12:18.842966Z",
     "start_time": "2018-02-07T09:12:17.211091Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "with open(db_path, 'wb') as handle:\n",
    "    pickle.dump(db, handle, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Query Against Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we load the database from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:14:27.591145Z",
     "start_time": "2018-02-07T09:14:26.777400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = {}\n",
    "with open(db_path, 'rb') as handle:\n",
    "    db = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:14:30.772571Z",
     "start_time": "2018-02-07T09:14:30.668112Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
