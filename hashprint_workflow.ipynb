{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Known-Artist Live Song ID: A Hashprint Approach\n",
    "\n",
    "This notebook is a python implementation of the [original matlab version] (http://pages.hmc.edu/ttsai/assets/livesongid.tar.gz). The pipeline consists of the following modules:\n",
    "\n",
    "1. Preprocessing with Constant-Q Transform (CQT)\n",
    "2. Learning PCA filters\n",
    "3. Obtaining hashprint representation by applying PCA filters to preprocessed CQT matrix\n",
    "4. Generating database with the hashprint of pitch-shifted CQT matrix of reference tracks\n",
    "5. Matching query against database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:38.148677Z",
     "start_time": "2018-02-09T03:35:38.140351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhwang/workspace/live-song-id\n"
     ]
    }
   ],
   "source": [
    "GIT_DIR = '/home/zhwang/workspace/live-song-id/'\n",
    "%cd $GIT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "For a given artist, we first preprocess the list of reference tracks by taking CQT transform for each audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:38.825794Z",
     "start_time": "2018-02-09T03:35:38.151232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "import os\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:38.834406Z",
     "start_time": "2018-02-09T03:35:38.827805Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# audio_path - where audio files are stored\n",
    "# list_dir - where list of softlinks are stored\n",
    "# cqt_dir - where results will be stored\n",
    "audio_path = '/home/zhwang/SoftLinks/' # change this\n",
    "list_dir = audio_path + '/Lists/'\n",
    "cqt_dir = '/home/zhwang/ttemp/livesong_results/' # change this\n",
    "artist = 'taylorswift'\n",
    "out_dir = os.path.join(cqt_dir, artist+'_out')\n",
    "file_paths = get_allpaths(artist, list_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T07:57:29.917108Z",
     "start_time": "2018-02-07T07:41:31.282369Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%cd $cqt_dir\n",
    "%mkdir $out_dir\n",
    "%cd $out_dir\n",
    "\n",
    "f = open(os.path.join(out_dir, artist + '_cqtList.txt'), 'w')\n",
    "for cur_file in file_paths:\n",
    "    print('==> Computing CQT of %s'%cur_file)\n",
    "    y, sr = librosa.load(audio_path + cur_file + '.wav')\n",
    "    Q = librosa.cqt(y, sr=sr, fmin=130.81, n_bins=121, bins_per_octave=24)\n",
    "    logQ = preprocess(Q, 3)\n",
    "    cur_file_path = os.path.join(os.getcwd(), cur_file + '.dat')\n",
    "    np.savetxt(cur_file_path, logQ)\n",
    "    f.write(cur_file_path + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning PCA Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:38.843337Z",
     "start_time": "2018-02-09T03:35:38.837471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhwang/workspace/live-song-id\n"
     ]
    }
   ],
   "source": [
    "%cd $GIT_DIR\n",
    "from PCA import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate the filters for the hashprint representation by taking PCA on the covariance matrix for all reference songs for this artist. First, we compute the covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:38.850083Z",
     "start_time": "2018-02-09T03:35:38.845991Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "nbins = 121\n",
    "m = 20 # number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T08:11:10.811072Z",
     "start_time": "2018-02-07T08:09:44.286845Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "f = open(os.path.join(out_dir, artist + '_cqtList.txt'), 'r')\n",
    "accum_cov = np.zeros((nbins * m, nbins * m))\n",
    "count = 0\n",
    "\n",
    "for line in f:\n",
    "    print('==> Computing covariance matrix for %s'%os.path.basename(line)[:-1])\n",
    "    Q = np.loadtxt(line[:-1])\n",
    "    A = getTDE(Q)\n",
    "    if A.shape[1] > 1:\n",
    "        accum_cov += np.cov(A.T)\n",
    "    count += 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute PCA from these covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T08:15:04.142290Z",
     "start_time": "2018-02-07T08:14:59.051592Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "evals, evecs = LA.eig(accum_cov / count)\n",
    "ind = np.argsort(-evals)\n",
    "evecs = (evecs[:, ind])[:, :num_features] # this turns out to be complex\n",
    "evecs = np.absolute(evecs)\n",
    "np.savetxt(os.path.join(out_dir, artist + '_model.dat'), evecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Filters to CQT Matrix to generate the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:39.106030Z",
     "start_time": "2018-02-09T03:35:38.852752Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evecs = np.loadtxt(os.path.join(out_dir, artist + '_model.dat')).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to stay consistency with the keras model, we transpose the filters and the CQT images to have shape ```(width, height)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:43.645417Z",
     "start_time": "2018-02-09T03:35:39.108991Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5103 on context None\n",
      "Preallocating 10867/11439 Mb (0.950000) on cuda\n",
      "Mapped name None to device cuda: Tesla K40c (0000:81:00.0)\n"
     ]
    }
   ],
   "source": [
    "pca_matrix = np.array([vec.reshape((m, -1)) for vec in evecs])\n",
    "delta = 16\n",
    "max_pitch_shift = 4\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each reference track, we pitch shift the CQT matrix by four pitches, both up and down. For each pitch-shifted version, we compute the hashprint by first passing it through the convolutional network, and then taking the delta feature and thresholding by zero.\n",
    "\n",
    "The database contains filenames as keys and the pitch-shifted delta features as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:10:01.359591Z",
     "start_time": "2018-02-07T09:09:21.358407Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generating database for taylorswift_ref1.dat\n",
      "==> Generating database for taylorswift_ref2.dat\n",
      "==> Generating database for taylorswift_ref3.dat\n",
      "==> Generating database for taylorswift_ref4.dat\n",
      "==> Generating database for taylorswift_ref5.dat\n",
      "==> Generating database for taylorswift_ref6.dat\n",
      "==> Generating database for taylorswift_ref7.dat\n",
      "==> Generating database for taylorswift_ref8.dat\n",
      "==> Generating database for taylorswift_ref9.dat\n",
      "==> Generating database for taylorswift_ref10.dat\n",
      "==> Generating database for taylorswift_ref11.dat\n",
      "==> Generating database for taylorswift_ref12.dat\n",
      "==> Generating database for taylorswift_ref13.dat\n",
      "==> Generating database for taylorswift_ref14.dat\n",
      "==> Generating database for taylorswift_ref15.dat\n",
      "==> Generating database for taylorswift_ref16.dat\n",
      "==> Generating database for taylorswift_ref17.dat\n",
      "==> Generating database for taylorswift_ref18.dat\n",
      "==> Generating database for taylorswift_ref19.dat\n",
      "==> Generating database for taylorswift_ref20.dat\n",
      "==> Generating database for taylorswift_ref21.dat\n",
      "==> Generating database for taylorswift_ref22.dat\n",
      "==> Generating database for taylorswift_ref23.dat\n",
      "==> Generating database for taylorswift_ref24.dat\n",
      "==> Generating database for taylorswift_ref25.dat\n",
      "==> Generating database for taylorswift_ref26.dat\n",
      "==> Generating database for taylorswift_ref27.dat\n",
      "==> Generating database for taylorswift_ref28.dat\n",
      "==> Generating database for taylorswift_ref29.dat\n",
      "==> Generating database for taylorswift_ref30.dat\n",
      "==> Generating database for taylorswift_ref31.dat\n",
      "==> Generating database for taylorswift_ref32.dat\n",
      "==> Generating database for taylorswift_ref33.dat\n",
      "==> Generating database for taylorswift_ref34.dat\n",
      "==> Generating database for taylorswift_ref35.dat\n",
      "==> Generating database for taylorswift_ref36.dat\n",
      "==> Generating database for taylorswift_ref37.dat\n",
      "==> Generating database for taylorswift_ref38.dat\n",
      "==> Generating database for taylorswift_ref39.dat\n",
      "==> Generating database for taylorswift_ref40.dat\n",
      "==> Generating database for taylorswift_ref41.dat\n",
      "==> Generating database for taylorswift_ref42.dat\n",
      "==> Generating database for taylorswift_ref43.dat\n",
      "==> Generating database for taylorswift_ref44.dat\n",
      "==> Generating database for taylorswift_ref45.dat\n",
      "==> Generating database for taylorswift_ref46.dat\n",
      "==> Generating database for taylorswift_ref47.dat\n",
      "==> Generating database for taylorswift_ref48.dat\n",
      "==> Generating database for taylorswift_ref49.dat\n",
      "==> Generating database for taylorswift_ref50.dat\n",
      "==> Generating database for taylorswift_ref51.dat\n",
      "==> Generating database for taylorswift_ref52.dat\n",
      "==> Generating database for taylorswift_ref53.dat\n",
      "==> Generating database for taylorswift_ref54.dat\n",
      "==> Generating database for taylorswift_ref55.dat\n",
      "==> Generating database for taylorswift_ref56.dat\n",
      "==> Generating database for taylorswift_ref57.dat\n",
      "==> Generating database for taylorswift_ref58.dat\n",
      "==> Generating database for taylorswift_ref59.dat\n",
      "==> Generating database for taylorswift_ref60.dat\n",
      "==> Generating database for taylorswift_ref61.dat\n",
      "==> Generating database for taylorswift_ref62.dat\n",
      "==> Generating database for taylorswift_ref63.dat\n",
      "==> Generating database for taylorswift_ref64.dat\n",
      "==> Generating database for taylorswift_ref65.dat\n",
      "==> Generating database for taylorswift_ref66.dat\n",
      "==> Generating database for taylorswift_ref67.dat\n",
      "==> Generating database for taylorswift_ref68.dat\n",
      "==> Generating database for taylorswift_ref69.dat\n",
      "==> Generating database for taylorswift_ref70.dat\n",
      "==> Generating database for taylorswift_ref71.dat\n"
     ]
    }
   ],
   "source": [
    "f = open(os.path.join(out_dir, artist + '_cqtList.txt'), 'r')\n",
    "db = {}\n",
    "\n",
    "for line in f:\n",
    "    print('==> Generating database for %s'%os.path.basename(line)[:-1])\n",
    "    Q = np.loadtxt(line[:-1]).T\n",
    "    pitch_shift_Qs = np.empty((2 * max_pitch_shift + 1, ) + Q.shape)\n",
    "    pitch_shift_Qs[0, :, :] = Q\n",
    "    for i in range(1, max_pitch_shift + 1):\n",
    "        pitch_shift_Qs[i, :, :] = pitch_shift_CQT(Q.T, i).T\n",
    "    for i in range(1, max_pitch_shift + 1):\n",
    "        pitch_shift_Qs[i + max_pitch_shift, :, :] = pitch_shift_CQT(Q.T, -i).T\n",
    "    \n",
    "    conv_1d_net = build_model(pca_matrix, Q.shape, delta=delta)\n",
    "    \n",
    "    fpseqs = run_model(conv_1d_net, pitch_shift_Qs)\n",
    "    delta_fp = fpseqs[:, :, :fpseqs.shape[2] - delta] - fpseqs[:, :, delta:]\n",
    "    \n",
    "    db[os.path.basename(line)[:-1]] = np.where(delta_fp > 0, 1, 0)\n",
    "f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the database, we serialize it and save it to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:43.650809Z",
     "start_time": "2018-02-09T03:35:43.647670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "db_path = os.path.join(out_dir, artist + '_db.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:12:18.842966Z",
     "start_time": "2018-02-07T09:12:17.211091Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "with open(db_path, 'wb') as handle:\n",
    "    pickle.dump(db, handle, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Query Against Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we load the database from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:44.378168Z",
     "start_time": "2018-02-09T03:35:43.652438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from search import *\n",
    "db = {}\n",
    "with open(db_path, 'rb') as handle:\n",
    "    db = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess the query by applying the PCA filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T03:35:57.267795Z",
     "start_time": "2018-02-09T03:35:44.380034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing CQT of taylorswift_query1\n",
      "==> Computing CQT of taylorswift_query2\n",
      "==> Computing CQT of taylorswift_query3\n",
      "==> Computing CQT of taylorswift_query4\n",
      "==> Computing CQT of taylorswift_query5\n",
      "==> Computing CQT of taylorswift_query6\n",
      "==> Computing CQT of taylorswift_query7\n",
      "==> Computing CQT of taylorswift_query8\n",
      "==> Computing CQT of taylorswift_query9\n",
      "==> Computing CQT of taylorswift_query10\n",
      "==> Computing CQT of taylorswift_query11\n",
      "==> Computing CQT of taylorswift_query12\n",
      "==> Computing CQT of taylorswift_query13\n",
      "==> Computing CQT of taylorswift_query14\n",
      "==> Computing CQT of taylorswift_query15\n",
      "==> Computing CQT of taylorswift_query16\n",
      "==> Computing CQT of taylorswift_query17\n",
      "==> Computing CQT of taylorswift_query18\n",
      "==> Computing CQT of taylorswift_query19\n",
      "==> Computing CQT of taylorswift_query20\n",
      "==> Computing CQT of taylorswift_query21\n",
      "==> Computing CQT of taylorswift_query22\n",
      "==> Computing CQT of taylorswift_query23\n",
      "==> Computing CQT of taylorswift_query24\n",
      "==> Computing CQT of taylorswift_query25\n",
      "==> Computing CQT of taylorswift_query26\n",
      "==> Computing CQT of taylorswift_query27\n",
      "==> Computing CQT of taylorswift_query28\n",
      "==> Computing CQT of taylorswift_query29\n",
      "==> Computing CQT of taylorswift_query30\n",
      "==> Computing CQT of taylorswift_query31\n",
      "==> Computing CQT of taylorswift_query32\n",
      "==> Computing CQT of taylorswift_query33\n",
      "==> Computing CQT of taylorswift_query34\n",
      "==> Computing CQT of taylorswift_query35\n",
      "==> Computing CQT of taylorswift_query36\n",
      "==> Computing CQT of taylorswift_query37\n",
      "==> Computing CQT of taylorswift_query38\n",
      "==> Computing CQT of taylorswift_query39\n",
      "==> Computing CQT of taylorswift_query40\n",
      "==> Computing CQT of taylorswift_query41\n",
      "==> Computing CQT of taylorswift_query42\n",
      "==> Computing CQT of taylorswift_query43\n",
      "==> Computing CQT of taylorswift_query44\n",
      "==> Computing CQT of taylorswift_query45\n",
      "==> Computing CQT of taylorswift_query46\n",
      "==> Computing CQT of taylorswift_query47\n",
      "==> Computing CQT of taylorswift_query48\n",
      "==> Computing CQT of taylorswift_query49\n",
      "==> Computing CQT of taylorswift_query50\n",
      "==> Computing CQT of taylorswift_query51\n",
      "==> Computing CQT of taylorswift_query52\n",
      "==> Computing CQT of taylorswift_query53\n",
      "==> Computing CQT of taylorswift_query54\n",
      "==> Computing CQT of taylorswift_query55\n",
      "==> Computing CQT of taylorswift_query56\n",
      "==> Computing CQT of taylorswift_query57\n",
      "==> Computing CQT of taylorswift_query58\n",
      "==> Computing CQT of taylorswift_query59\n",
      "==> Computing CQT of taylorswift_query60\n",
      "==> Computing CQT of taylorswift_query61\n",
      "==> Computing CQT of taylorswift_query62\n",
      "==> Computing CQT of taylorswift_query63\n",
      "==> Computing CQT of taylorswift_query64\n",
      "==> Computing CQT of taylorswift_query65\n",
      "==> Computing CQT of taylorswift_query66\n",
      "==> Computing CQT of taylorswift_query67\n",
      "==> Computing CQT of taylorswift_query68\n",
      "==> Computing CQT of taylorswift_query69\n",
      "==> Computing CQT of taylorswift_query70\n",
      "==> Computing CQT of taylorswift_query71\n",
      "==> Computing CQT of taylorswift_query72\n",
      "==> Computing CQT of taylorswift_query73\n",
      "==> Computing CQT of taylorswift_query74\n",
      "==> Computing CQT of taylorswift_query75\n",
      "==> Computing CQT of taylorswift_query76\n",
      "==> Computing CQT of taylorswift_query77\n",
      "==> Computing CQT of taylorswift_query78\n",
      "==> Computing CQT of taylorswift_query79\n",
      "==> Computing CQT of taylorswift_query80\n",
      "==> Computing CQT of taylorswift_query81\n",
      "==> Computing CQT of taylorswift_query82\n",
      "==> Computing CQT of taylorswift_query83\n",
      "==> Computing CQT of taylorswift_query84\n",
      "==> Computing CQT of taylorswift_query85\n",
      "==> Computing CQT of taylorswift_query86\n",
      "==> Computing CQT of taylorswift_query87\n",
      "==> Computing CQT of taylorswift_query88\n",
      "==> Computing CQT of taylorswift_query89\n",
      "==> Computing CQT of taylorswift_query90\n",
      "==> Computing CQT of taylorswift_query91\n",
      "==> Computing CQT of taylorswift_query92\n",
      "==> Computing CQT of taylorswift_query93\n",
      "==> Computing CQT of taylorswift_query94\n",
      "==> Computing CQT of taylorswift_query95\n",
      "==> Computing CQT of taylorswift_query96\n",
      "==> Computing CQT of taylorswift_query97\n",
      "==> Computing CQT of taylorswift_query98\n",
      "==> Computing CQT of taylorswift_query99\n",
      "==> Computing CQT of taylorswift_query100\n"
     ]
    }
   ],
   "source": [
    "query_paths = get_allpaths(artist, list_dir, file_type='query')\n",
    "def get_query_shape():\n",
    "    '''\n",
    "        returns the shape of query file in (width, height)\n",
    "    '''\n",
    "    assert len(query_paths) > 0\n",
    "    cur_file = query_paths[0]\n",
    "    y, sr = librosa.load(audio_path + cur_file + '.wav')\n",
    "    Q = librosa.cqt(y, sr=sr, fmin=130.81, n_bins=121, bins_per_octave=24)\n",
    "    logQ = preprocess(Q, 3)\n",
    "    return logQ.T.shape\n",
    "\n",
    "query_shape = get_query_shape()\n",
    "querys = np.empty((len(query_paths), ) + query_shape)\n",
    "\n",
    "for i in range(len(query_paths)):\n",
    "    cur_file = query_paths[i]\n",
    "    print('==> Computing CQT of %s'%cur_file)\n",
    "    y, sr = librosa.load(audio_path + cur_file + '.wav')\n",
    "    Q = librosa.cqt(y, sr=sr, fmin=130.81, n_bins=121, bins_per_octave=24)\n",
    "    logQ = preprocess(Q, 3)\n",
    "    querys[i, :, :] = logQ.T\n",
    "\n",
    "conv_1d_net = build_model(pca_matrix, query_shape, delta=delta)\n",
    "fpseqs = run_model(conv_1d_net, querys)\n",
    "delta_fp = fpseqs[:, :, :fpseqs.shape[2] - delta] - fpseqs[:, :, delta:]\n",
    "query_reps = np.where(delta_fp > 0, 1, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we run the cross-correlation search algorithm on each of the query representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T04:39:06.936773Z",
     "start_time": "2018-02-09T03:35:57.271022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Matching query 0; Time elapsed: 61 seconds\n",
      "-- Matching query 1; Time elapsed: 61 seconds\n",
      "-- Matching query 2; Time elapsed: 62 seconds\n",
      "-- Matching query 3; Time elapsed: 60 seconds\n",
      "-- Matching query 4; Time elapsed: 63 seconds\n",
      "-- Matching query 5; Time elapsed: 62 seconds\n",
      "-- Matching query 6; Time elapsed: 63 seconds\n",
      "-- Matching query 7; Time elapsed: 64 seconds\n",
      "-- Matching query 8; Time elapsed: 62 seconds\n",
      "-- Matching query 9; Time elapsed: 61 seconds\n",
      "-- Matching query 10; Time elapsed: 62 seconds\n",
      "-- Matching query 11; Time elapsed: 63 seconds\n",
      "-- Matching query 12; Time elapsed: 61 seconds\n",
      "-- Matching query 13; Time elapsed: 62 seconds\n",
      "-- Matching query 14; Time elapsed: 62 seconds\n",
      "-- Matching query 15; Time elapsed: 62 seconds\n",
      "-- Matching query 16; Time elapsed: 63 seconds\n",
      "-- Matching query 17; Time elapsed: 63 seconds\n",
      "-- Matching query 18; Time elapsed: 64 seconds\n",
      "-- Matching query 19; Time elapsed: 62 seconds\n",
      "-- Matching query 20; Time elapsed: 63 seconds\n",
      "-- Matching query 21; Time elapsed: 62 seconds\n",
      "-- Matching query 22; Time elapsed: 61 seconds\n",
      "-- Matching query 23; Time elapsed: 61 seconds\n",
      "-- Matching query 24; Time elapsed: 62 seconds\n",
      "-- Matching query 25; Time elapsed: 62 seconds\n",
      "-- Matching query 26; Time elapsed: 63 seconds\n",
      "-- Matching query 27; Time elapsed: 61 seconds\n",
      "-- Matching query 28; Time elapsed: 62 seconds\n",
      "-- Matching query 29; Time elapsed: 62 seconds\n",
      "-- Matching query 30; Time elapsed: 64 seconds\n",
      "-- Matching query 31; Time elapsed: 62 seconds\n",
      "-- Matching query 32; Time elapsed: 63 seconds\n",
      "-- Matching query 33; Time elapsed: 61 seconds\n",
      "-- Matching query 34; Time elapsed: 60 seconds\n",
      "-- Matching query 35; Time elapsed: 59 seconds\n",
      "-- Matching query 36; Time elapsed: 60 seconds\n",
      "-- Matching query 37; Time elapsed: 60 seconds\n",
      "-- Matching query 38; Time elapsed: 59 seconds\n",
      "-- Matching query 39; Time elapsed: 60 seconds\n",
      "-- Matching query 40; Time elapsed: 60 seconds\n",
      "-- Matching query 41; Time elapsed: 59 seconds\n",
      "-- Matching query 42; Time elapsed: 59 seconds\n",
      "-- Matching query 43; Time elapsed: 60 seconds\n",
      "-- Matching query 44; Time elapsed: 59 seconds\n",
      "-- Matching query 45; Time elapsed: 60 seconds\n",
      "-- Matching query 46; Time elapsed: 60 seconds\n",
      "-- Matching query 47; Time elapsed: 61 seconds\n",
      "-- Matching query 48; Time elapsed: 61 seconds\n",
      "-- Matching query 49; Time elapsed: 62 seconds\n",
      "-- Matching query 50; Time elapsed: 63 seconds\n",
      "-- Matching query 51; Time elapsed: 63 seconds\n",
      "-- Matching query 52; Time elapsed: 61 seconds\n",
      "-- Matching query 53; Time elapsed: 62 seconds\n",
      "-- Matching query 54; Time elapsed: 65 seconds\n",
      "-- Matching query 55; Time elapsed: 63 seconds\n",
      "-- Matching query 56; Time elapsed: 63 seconds\n",
      "-- Matching query 57; Time elapsed: 62 seconds\n",
      "-- Matching query 58; Time elapsed: 63 seconds\n",
      "-- Matching query 59; Time elapsed: 63 seconds\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8c2dcdfe1716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mground_truths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_querytoref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateMRR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'==> MRR for %s is %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/live-song-id/search.py\u001b[0m in \u001b[0;36mcalculateMRR\u001b[0;34m(queries, refs, groundTruth)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mMRR\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mt_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         print('-- Matching query %d; Time elapsed: %d seconds'\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "querys = [q for q in query_reps]\n",
    "refs = list(db.values())\n",
    "ground_truths = get_querytoref(artist, list_dir)\n",
    "mrr = calculateMRR(querys, refs, ground_truths)\n",
    "print('==> MRR for %s is %d'%(artist, mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
